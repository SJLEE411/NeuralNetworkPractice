{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a040b0",
   "metadata": {},
   "source": [
    "### Hello World of Neural Network\n",
    "#### MNIST is a set of images of handwritten digits\n",
    "#### The problem is to classify each greyscale image into the corret category, namely '0', '1'..., '9'\n",
    "#### There are 60000 training images and 10000 images\n",
    "\n",
    "Each image is a data point and it is called sample\n",
    "And each data points typically belong to one or more categories\n",
    "Each Mnist image belongs to exactly one category or class 0,1,2. etc.\n",
    "The class of a sample is known as its label\n",
    "\n",
    "1. load\n",
    "2. preprocess\n",
    "3. build network\n",
    "4. train\n",
    "5. test\n",
    "\n",
    "The Mnist dataset is one of several Tensorflow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfa5fc",
   "metadata": {},
   "source": [
    "### 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ef3cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (3.0.5)\n",
      "Requirement already satisfied: absl-py in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (1.24.3)\n",
      "Requirement already satisfied: rich in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (13.7.0)\n",
      "Requirement already satisfied: namex in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (3.9.0)\n",
      "Requirement already satisfied: dm-tree in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (0.1.8)\n",
      "Requirement already satisfied: ml-dtypes in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from keras) (0.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sangjunelee/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07753135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebef2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90dd9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7bd57",
   "metadata": {},
   "source": [
    "#### Data is stored in special multidimensional arrays tensors, There are 60000 greyscale images in the training set, Each image is 28pxl x 28pxl\n",
    "    - the training set is a data container with 60000 x 28 x 28 elements\n",
    "    - the training lavels are stored in a 60000 element vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c85406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape\n",
      "\ttraining images: (60000, 28, 28)\n",
      "\ttraining labels: (60000,)\n",
      "\ttest images:\t (10000, 28, 28)\n",
      "\ttest labels:\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('tensor shape')\n",
    "print('\\ttraining images:', train_images.shape)\n",
    "print('\\ttraining labels:', train_labels.shape)\n",
    "print('\\ttest images:\\t', test_images.shape)\n",
    "print('\\ttest labels:\\t', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5e65b",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "The data has to be 'reshaped' to a form that is acceptable to the network\n",
    "\n",
    "The network will expect samples as vectors (1D arrays) of floating point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f2b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  7\n"
     ]
    }
   ],
   "source": [
    "# inspect the first image using the matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "xmpl_image = test_images[0]\n",
    "xmpl_label = test_labels[0]\n",
    "print('samples:')\n",
    "plt.imshow(xmpl_image, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "# check the label is correct\n",
    "print('label: ', xmpl_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15af3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape flattens 28 x 28 array to a vector of 784 elements\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "\n",
    "#cast as floats and rescale from to [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447a088",
   "metadata": {},
   "source": [
    "#### The network is also expecting categorically encoded labels\n",
    "a vector with a single nonzero element corresponding to the category\n",
    "\n",
    "Each label will be turned in to a 10 element vector with a single 'hot' nonzero entry\n",
    "\n",
    "for example 7 is encoded as (0,0,0,0,0,0,0,1,0,0)\n",
    "\n",
    "One - hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdf059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'7' as one-hot vector:\t[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# encode with the convenient to_categorical function\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "orig_label = test_labels[0]\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "#check encoding\n",
    "print('\\'', orig_label, '\\'', ' as one-hot vector:\\t', test_labels[0], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d9f8d",
   "metadata": {},
   "source": [
    "### 3. Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae2438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty network\n",
    "from keras.models import Sequential\n",
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74db31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add two layers\n",
    "from keras.layers import Dense, Input\n",
    "# Add the first layer with Input shape\n",
    "network.add(Input(shape=(28 * 28, )))\n",
    "\n",
    "# Add the subsequent layers\n",
    "network.add(Dense(512, activation='relu'))\n",
    "network.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625836c",
   "metadata": {},
   "source": [
    "The second softmax layer outputs a vector whose elements form a probability distribution\n",
    "\n",
    "    - the numbers are nonnegative and sum to one - a probability distribution\n",
    "    - outputs are interpreted as probabilities of membership of each class: the probability that the input sample is labeled '0' or '1' or '2' and so on\n",
    "\n",
    "\n",
    "However the network is not yet ready. We must specify a loss function, an optimiser and one or more training metrics\n",
    "\n",
    "The loss function quantifies how far off the network prediction is from the target\n",
    "\n",
    "The optimiser makes parameter adjustments in the training loop and metrics report on progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de0dfa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer ='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "#rmsprop is one of several tensorflow.keras optimizer\n",
    "#Categorical crossentropy is the preferred loss for single label multiclass problems\n",
    "#accuracy is the fraction of correctly classified samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ab926",
   "metadata": {},
   "source": [
    "### 4. Train\n",
    "\n",
    "We have to decide:\n",
    "\n",
    "    - the number of samples processed in a single pass of the training algorithm - the mini-batch size\n",
    "    - the number of complete passes through the entire training set - the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d05e7b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.4403\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1154\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0710\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0547\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x284593750>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training - fit to input data\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df013b9b",
   "metadata": {},
   "source": [
    "### 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab73659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.9749 - loss: 0.0766\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae927c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.2000514e-09, 2.9361751e-09, 3.8711210e-06, 2.5862901e-05,\n",
       "        3.9980144e-11, 1.0089801e-07, 5.6675536e-13, 9.9996960e-01,\n",
       "        9.5197286e-08, 5.2229348e-07]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network prediction for a single sample\n",
    "# ten numbers, each a probability of class membership\n",
    "network.predict(test_images[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c71c41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the most probable class?\n",
    "# the index of the largest element of the output vector\n",
    "import numpy as np\n",
    "np.argmax(network.predict(test_images[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35e9cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# does the prediction agree with the label?\n",
    "raw_label_vector = test_labels[0]\n",
    "\n",
    "predicated_label = np.argmax(raw_label_vector)\n",
    "print(predicated_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bd6b801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape the first test image back to its original shape\n",
    "image_to_show = test_images[0].reshape((28, 28))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_to_show, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c478d",
   "metadata": {},
   "source": [
    "Remember that the network does not have eyes and a visual cortex. The network only mapped 784 element vector to a 10 component probability factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d62c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
